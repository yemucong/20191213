# net
### Abstracts
+ 在语义分割领域，将不同阶段的特征进行融合是常用的方法。低层特征具有较强的边界和纹理信息，而高层特征具有较强的语义信息，低层特征和高层特征具有较大的语义差距，直接将高层和低层特征进行融合会存在很大的噪声，直接融合并不能产生最好的效果。为了解决这个问题，我们遵循编码器和解码器的思想设计了一个并行金字塔网络，我们命名为NET。我们使用SEM来增强低层特征的特征值，使其具有更强的语义信息并缩短其与高层特征的语义差距。 我们使用PPM（金字塔池化模块）来聚合不同区域的上下文信息，并不断融合不同阶段的被SEM增强的特征（feature map）。将融合后的特征采用CAM来消除特征值融合后产生的噪声。最后，我们为了提取边界信息，设计了一个BEM在最后阶段获取边界信息并融合。我们在提出的并行金字塔网络中嵌入这四种模块从而达到对图像的精确分割。我们在三个数据集city、voc、camvid上进行实验验证我们网络的效果，最终都得到了最优的效果。
### 1.Introduce
+ 语义分割是计算机视觉领域一个非常活跃的研究方向，该技术的研究目的是对图像中的每个像素能够正确地预测出该像素属于的物体类别，它在视频监控、场景分析、人机交互以及行为分析等方面有着巨大的应用潜力。
+ State-of-the-art semantic segmentation are mostly based on the *fully convolutional network*(FCN).该方法的出色之处在于，其利用了现存的CNN网络作为其模块之一来产生层次化的特征。目前大多数的基于FCN的方法倾向于构建一个编码器分支来逐步获取语义信息，然后使用解码器来逐步恢复分辨率信息。experiences[24, 2, 3] show that ~~multi-scale~~（多阶段） information would help resolve ambiguous cases and results in more robust classification。为了捕捉多层次的上下文信息，跳跃连接在编码器和解码器的架构中经常被使用，跳跃连接将低层特征和高层特征进行融合，但是我们发现，这种架构存在很严重的问题，我们在使用跳跃连接来聚合特征时，没有考虑到低层信息和深层信息的语义鸿沟，直接将其进行融合会产生负面的效果。一些工作使用空洞卷积在使用低层特征前进行语义增强，缩短低层特征和高层特征之前的差距，但少有研究在特征融合后对融合后的特征值进行处理，消除融合后产生的噪声。我们展示一些feature heat map in Fig.1，
+ **写在图下作为解释：**(a),(b),(c)为FCN三个阶段不断加深的图(g)的热图，可以看出他们之前存在巨大的语义差距。(d)为(b)增强后的热图，其与(d)的差距明显小于(b)与(d)的差距。(e)为(b)和(c)做sum后产生的特征图。看出其噪声很大，产生了负面效果。(f)为(e)经过消除噪声的热图，(f)比(e)有更强的鲁棒性。
![a, layer1](20191219200837396_28432.png)
![b, layer3](20191219200904701_17606.png)
![c, layer4](20191219200928295_15937.png)
![d, layer3_sem_1](20191219200947213_32364.png)
![e, layer3layer4_75](20191219201015527_8906.png)
![f, dp3](20191219201158280_1792.png)
![g, data](20191219201230731_9879.jpg)
![h, gt](20191219201249095_25240.png)
![i, our](20191219201412609_8184.png)
+ (a),(b),(c)是来自FCN三个阶段的特征图，我们发现越低层次的边界信息越明显，在fig(a)中我们很明显的能看出其边界和纹理（天空、柱子），但其干扰项太多，较为粗糙，不利于我们将其作为特征图进行精确分割。越深层次的特征(b)(c)边界信息越模糊，取而代之的是深层次的抽象的语义信息，其包含更多的鉴别和分类信息，可以用于分割。(e)展示了传统的跳跃连接将低层特征(b)和高层特征(c)sum后产生的结果，可以看出虽然特征图得到了加强，但其简单的sum后产生了很多噪声，产生了很多负面效果。所以，我们在特征融合时，不能忽略高层和低层特征之前的鸿沟。但目前工作很少有人提出解决方案。
+ 为了解决上述问题，我们认为在聚合不同阶段特征时，不能简单的将不同阶段的特征进行融合就进行使用。所以我们在使用不同阶段的低层特征前应尽可能的减少其与高层特征之间的语义差距。我们需要在融合不同尺度特征前后对特征图进行处理。在融合前我们应提高低层特征的语义信息，减小其边界和纹理信息，提取更强的语义信息，使得低层特征与高层之前具有较小的差异。在融合后，我们仍需要对融合后的特征图做处理，进一步消除噪声项。此外，我们发现最低层次的特征不利于做分割，但较低层的特征图被我们增强后会丢失大量边界信息，所以，我们需要一个模块来专门获取低层特征的边界信息。综上，我们提出了自己的网络来解决这个问题并提高分割性能。
+ our main contributions can be summarized as follow：
1. 提出了CAM模块用以消除不同层次特征图融合后产生的噪声
2. 一个BGM模块获取边界信息
3. 提出一个基于编解码的并行金字塔网络提高语义分割的性能
### 2.Relative Work
#### Encoder-Decoder
+ 在基于深度神经网络的图像语义分割方法中,比较经典的是编解码(Encoder-Decoder)结构的方法。该类方法的网络结构如图2所示。2014年, Long等提出的全卷积网络,是第一个使用类似编解码方法的网络。但由于其直接对原图进行填充,引入了噪声,且未考虑有用的上下文信息,导致分割精度不高,参数规模巨大,计算效率欠佳。2015年,基于FCN框架, Badrinarayanan等提出了Seg Net网络 ,它是典型的编码-解码网络,用于道路、车辆的分割。该网络的优点在于池化层记录像素点的空间位置,在后续恢复图像分辨率时,能够有效地将其映射回对应位置,保留像素空间信息;然而,SegNet不能很好地识别物体轮廓,物体边缘的分割精度较差。此外, Noh等提出的DeconvNet对卷积层进行镜像处理,构成Encoder-Decoder结构,以编解码结构改善了FCN效果。随后, Hong等模仿DeconvNet,在FCN的基础上将卷积层与全连接层全部进行镜像处理,导致网络结构的参数规模很大,结果不如DeconvNet, Paszke等提出的ENet在卷积之间添加BN层和ReLU,依然采用Encoder-Decoder结构,分割效果较好。Yang等提出的CEDN,在使用Encoder-Decoder结构的同时,采用contour概率图结合MCG方法进行分割,效果良好,但速度较慢。
#### 基于多尺度信息的方法
+ 为了扩大感受野,有效地利用上下文信息,Yu等提出了空洞卷积(Dilated Convolutions)模型。该结构能够在避免空间层级化信息丢失的同时,保留图像的内部数据结构,解决了语义分割任务的瓶颈问题。Chen等和Wang等对空洞卷积进行了更详细的讨论。此后,研究者们发现多尺度可以使模型表现得更好。2017年,Chen等提出了DeepLabv2版本,在v1版本上增加了一个多视野域,打造多尺度以提高模型的表现力,该结构被称为基于洞的空间金字塔(Atrous Spatial Pyramid Pooling, ASPP)。同年,Chen等提出的DeepLabv3在v2版本的基础上改进了ASPP模块,加入了1×1的卷积层和全局平均池化层。DeepLabv3使用空洞卷积与空间金字塔池化结构,在该结构之后, DeepLabv3还对特征图进行了8倍或16倍的上采样。但该方法较为粗糙,导致场景中的细节信息被忽略。针对当前语义分割丢失信息的问题,2017年, Lin等提出了RefineNet网络,其使用链式残差连接,能够有效地将下采样中缺失的信息进行融合,从而产生高分辨率的预测图像。2017年, Zhao等提出的PSPNet也使用空洞卷积改善 ResNet结构,并添加了一个金字塔池化模块。金字塔池化模块使用大内核池化层来捕获全局信息,其中内核分别覆盖了图像的整个区域、半个区域和小块区域。同年, Yu等提出了判别特征网络(Discriminative Feature Network, DFN) 。该网络利用注意力模块(Convolutional Block Attention Module, CBAM)选择更具判别力的特征, ,有效解决了语义分割的两个基本问题:类内不一致与类间无差别问题。Zhang等提出上下文语义编码模块与类别预测模块,在某种程度上减轻了分割问题中类间样本不均衡的问题。
### NET
+ 在这一章节中，我们首先分别介绍SEM、BEM和CAM的实现细节，并在下文出我们的网络整体架构，展示如何将这些模块嵌入网络。最后我们介绍使用的loss函数
+ 1.SEM
![SEM](20191220151736517_30020.png)
正如前文所说的，在特征融合前，我们首先对低层特征进行增强，缩短低层特征和高层特征之前的差距。
+ 2.BAM
+ 3.CAM
![CAM](20191220142348096_13041.png)
+ 4.Overall
+ 5.Loss
