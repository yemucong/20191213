# net
### Abstract
+ 在语义分割领域，将不同尺度的特征进行融合是常用的方法。低层特征具有较强的边界和纹理信息，而高层特征具有较强的语义信息。直接将高层和低层特征进行融合会存在很大的噪声，可能会对模型产生负面的影响。因为低层特征和高层特征具有较大的语义差距，直接融合并不能产生最好的效果。为了解决这个问题，我们提出了context aggregation module(信息聚合模块)(CAM)和boundary gain module(边界获取模块)(BGM)。CAM采用不同等级的下采样和上采样来消除特征融合后产生的巨大噪声，BGM在获取边界信息时去掉了具体的纹理信息，仅保留边界信息，使得网络具有更强的鲁棒性。此外我们还使用PPM(金字塔池化模块)和SEM(语义增强模块)分别用来捕捉全局上下文信息和增强低层语义特征。我们设计了一个并行金字塔网络整合各个模块来捕捉和聚合多尺度的特征，我们命名为NET。我们在city、voc、camvid上进行实验验证我们网络的效果，最终都得到了不错的效果。
### 1.Introduce
+ 语义分割是计算机视觉领域一个非常活跃的研究方向，该技术的研究目的是对图像中的每个像素能够正确地预测出该像素属于的物体类别，它在视频监控、场景分析、人机交互以及行为分析等方面有着巨大的应用潜力。
+ State-of-the-art semantic segmentation are mostly based on the *fully convolutional network*(FCN).该方法的出色之处在于，其利用了现存的CNN网络作为其模块之一来产生层次化的特征。目前大多数的基于FCN的方法倾向于构建一个编码器分支来逐步获取语义信息，然后使用解码器来逐步恢复分辨率信息。为了捕捉多尺度上下文信息，跳跃连接在编码和解码过程中经常被使用。在这种架构中，低层特征具有更详细的边界和纹理信息，深层特征则具有更强的语义信息来区分不同的类。跳跃连接将低层和深层信息进行聚合，获得更强的语义信息。但是我们发现，这种架构存在很严重的问题，我们在使用跳跃连接来聚合信息时，没有考虑到低层信息和深层信息的语义差距， 我们展示一些feature heat map in Fig.1，如图所示，(a)，(b)是来自FCN不同层次的特征图，(a)为浅层特征图，(b)为深层特征图，(c)是将(a)和(b)做sum后产生的特征图。我们发现直接将浅层特征和深层特征进行聚合会产生很多噪声，从而影响结果。
+ 综上，我们认为在聚合不同尺度信息时，不能简单的将不同尺度的特征进行融合就进行使用。所以我们在使用不同阶段的低层特征前应尽可能的减少其与高层特征之间的语义差距。我们需要在融合不同尺度特征前后对特征图进行处理。在融合前我们应提高低层特征的语义信息，减小其边界和纹理信息，使得低层特征与高层之前具有较小的差异。在融合后，我们仍需要消除低层特征和高层特征融合后带来的巨大噪声。此外，我们发现使用增强后的低层特征会丢失边界信息，然而边界信息对结果的提升至关重要，所以我们需要一个模块来专门获取低层特征的边界信息。我们还发现过多的使用边界信息对结果有负面影响，所以我们仅在最底层特征时获取其边界信息进行融合，避免过多的边界信息对结果造成影响。
+ our main contributions can be summarized as follow：
1. 我们提出了一个反向并行金字塔网络提高了其在语义分割领域的表达能力
2. 一个CAM模块来消除低层特征和高层特征融合后的噪声
3. 一个BGM模块获取边界信息
### Relative Work
~~+ FCN时语义分割的开创式模型，该模型使用VGG-16作为骨架网络，融合了VGG-16中的不同层级特征来获得最终的语义分割结果。FCN方法证明了浅层特征的融合有利于提升语义分割结果，所以U-Net将所有层次的特征全部都融合起来，从而形成一个U型网络结构。SegNet则和U-net大同小异，都是编码-解码结果。区别在意，SegNet没有直接融合不同尺度的层的信息，为了解决为止信息丢失的问题，SegNet使用了带有坐标（index）的池化，解决了由于多次池化造成的位置信息的丢失。~~
+ 接下来我们将总结语义分割领域常用的几种方法
~~+ 整合上下文知识
语义分割需要对多种空间尺度的信息予以整合，也需要对局部与全局信息进行平衡。一方面，细粒度的或者局部的信息对于提高像素级别的标注的正确率来说是关键的；另一方面，整合图像全局的上下文信息对于解决局部模糊性问题来说也是重要的。FCN时语义分割的开创式模型，该模型使用VGG-16作为骨架网络，融合了VGG-16中的不同层级特征来获得最终的语义分割结果。FCN方法证明了浅层特征的融合有利于提升语义分割结果，所以U-Net将所有层次的特征全部都融合起来，从而形成一个U型网络结构。SegNet则和U-net大同小异，都是编码-解码结果。区别在意，SegNet没有直接融合不同尺度的层的信息，为了解决为止信息丢失的问题，SegNet使用了带有坐标（index）的池化，解决了由于多次池化造成的位置信息的丢失。~~
+ 多尺度预测
Raj等人提出了全卷积VGG-16的一种多尺度版本，有着两个路径，一个是在原始分辨率上处理输入，使用的是一个浅层的卷积网络，再一个就是在两倍分辨率上处理，使用全卷积VGG-16和一个额外的卷积层。第二个路径的结果经过上采样后与第一个路径的结果相结合，这个串联起来的结果再经过一系列的卷积层，得到最终的输出。这样，这个网络便对尺度变换更加鲁棒了。Roy等人采取了另外的方法解决这个问题，他们选用了包含4个多尺度CNN的网络，而这4个网络有着相同的架构，取自Eigen等人。其中之一致力于为当前场景找出语义标签。这个网络（整体上）以一个从粗糙到精细的尺度序列来逐步的提取特征。另一个重要的工作是Bian等人[76]提出的网络，这个网络包含n个FCN，可以处理不同尺度的问题。该网络提取的特征将融合在一起（先使用合适的填充方法进行必要的上采样），然后通过一个额外的卷积层之后得到最终的分割结果。
+ 特征融合
再分割问题中，向全卷积神经网络架构中加入上下文信息的另一种方式便是进行特征融合。特种融合技术将一个全局特征（由某网络中较前面的层提取得到）与一个相对局部的特征映射（后边的层提取得）相结合。常见的架构如原始FCN网络利用跳跃连接的方式进行延迟特征融合，也是通过将不用层产生的特征映射相结合。另一种方法便是提前融合，这一方法来自ParseNet[77]中的上下文模块。全局特征被反池化为与局部特征相同的尺寸，然后，将这两种特征进行串联后得到一个合并的特征，输入到下一层或者直接用于分类器的学习，SharpMask[84] 这个工作继续发展了这种特征融合的想法，其引入了一种先进的调优模块来将前面层产生的特征合并到后面的层，这个模块使用的是一种自上而下的架构。
+ 扩张的（dilated）卷积
使用扩张卷积的最重要的工作便是Yu等人[71]提出的多尺度上下文聚合模型、上文提及的DeepLab模型（其升级版本）[69]、以及实时处理网络ENet[72]。所有这些将越来越大的各种扩张率结合，使得模型具有更大的感受野，同时不增添额外的消耗，也不会过度地对特征映射进行下采样。这些工作同时具有相同的趋势：扩张卷积与紧密多尺度上下文聚合紧密耦合，这我们将在后面章节中解释。
### NET
+ 